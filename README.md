# Scale your Python Code with PySpark in Apache Spark
## PyData Charlotte - January 2020 Meeting

<h3 align="right">Colby T. Ford, Ph.D.</h3>

----------------------------------------

If you don't have access to a Spark cluster, sign up for Databricks Community Edition: [https://databricks.com/signup/signup-community](https://databricks.com/signup/signup-community)


- If you're using Databricks (either Azure Databricks, Databricks on AWS, or Databricks Community Edition), you can import the tutorial notebook using this url: `.../PyDataCLT_Jan2020.dbc`

- If you're using a different type of Spark cluster, you can import the `.../PyDataCLT_Jan2020.ipynb` notebook.

- If you're just following along, you can see the tutorial notebook from your web browsers after downloading the `.../PyDataCLT_Jan2020.html` file.

----------------------------------------

## Resources:
- Databricks Documentation: [https://docs.databricks.com/](https://docs.databricks.com/)
- Azure Databricks Information: [https://docs.microsoft.com/en-us/azure/azure-databricks/](https://docs.microsoft.com/en-us/azure/azure-databricks/)
- PySpark API Documentation: [https://spark.apache.org/docs/latest/api/python/index.html](https://spark.apache.org/docs/latest/api/python/index.html)
- Databricks Academy: [https://academy.databricks.com/](https://academy.databricks.com/)
- Sparkitecture: [https://www.sparkitecture.io/](https://www.sparkitecture.io/)
